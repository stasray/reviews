import streamlit as st
import pandas as pd
import plotly.express as px

from services import generate_fake_reviews, run_analysis
from file_processing import load_reviews_from_file
from sentiment_analysis import get_hf_logs
from models import Review
from export_utils import render_export_buttons

st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–æ–≤", layout="wide")
st.title("–ê–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–æ–≤")

with st.sidebar:
    st.header("–î–∞–Ω–Ω—ã–µ")
    uploaded_file = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª (CSV/TSV/XLSX)", type=["csv", "tsv", "xlsx"]
    )
    st.caption("–°—Ç–æ–ª–±–µ—Ü —Å —Ç–µ–∫—Å—Ç–æ–º –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª—ë–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `text`, `review`, `–û—Ç–∑—ã–≤`).")
    st.divider()
    st.subheader("–ò–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–µ")
    num_reviews = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤", 5, 200, 50, step=5)
    generate_btn = st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–∑—ã–≤—ã")
    st.divider()
    st.header("–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (–ò–ò)")
    use_ai = st.checkbox("–û–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –ò–ò (Hugging Face API)", value=False)
    model_choice = st.selectbox(
        "–ú–æ–¥–µ–ª—å",
        options=[
            "auto (recommended)",
            "lxyuan/distilbert-base-multilingual-cased-sentiments-student",
            "nlptown/bert-base-multilingual-uncased-sentiment",
            "custom...",
        ],
        index=0,
    )
    if model_choice == "custom...":
        hf_model = st.text_input("–£–∫–∞–∂–∏—Ç–µ –º–æ–¥–µ–ª—å HF", value="nlptown/bert-base-multilingual-uncased-sentiment")
    else:
        hf_model = model_choice
    hf_token = st.text_input("HF API Token", type="password", help="–°–æ–∑–¥–∞–π—Ç–µ —Ç–æ–∫–µ–Ω –Ω–∞ huggingface.co/settings/tokens")

reviews: list[Review] | None = None

if uploaded_file is not None and st.button("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª"):
    file_bytes = uploaded_file.getvalue()
    try:
        reviews = load_reviews_from_file(file_bytes, uploaded_file.name)
        st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(reviews)}")
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")

if reviews is None and generate_btn:
    reviews = generate_fake_reviews(num_reviews)
    st.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(reviews)}")

if reviews:
    # Determine if AI can actually be used (token and model present)
    effective_use_ai = bool(use_ai and hf_token and hf_model)
    if use_ai and not effective_use_ai:
        st.warning("–ò–ò-–∞–Ω–∞–ª–∏–∑ –Ω–µ –±—ã–ª –∑–∞–ø—É—â–µ–Ω: —É–∫–∞–∂–∏—Ç–µ –≤–∞–ª–∏–¥–Ω—ã–π HF API Token –∏ –º–æ–¥–µ–ª—å.")

    # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    st.info("üîÑ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞... –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–π–º–µ—Ç 1-2 –º–∏–Ω—É—Ç—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.")
    
    analysis = run_analysis(
        reviews,
        use_ai=effective_use_ai,
        hf_model=hf_model if effective_use_ai else None,
        hf_token=hf_token if effective_use_ai else None,
    )

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ", analysis.stats["sentiment_counts"].get("positive", 0))
    with col2:
        st.metric("–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ", analysis.stats["sentiment_counts"].get("neutral", 0))
    with col3:
        st.metric("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ", analysis.stats["sentiment_counts"].get("negative", 0))

    st.subheader("–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å")
    sent_df = (
        pd.DataFrame(
            [
                {"sentiment": k, "count": v}
                for k, v in analysis.stats["sentiment_counts"].items()
            ]
        )
        .sort_values("count", ascending=False)
    )
    fig_sent = px.bar(sent_df, x="sentiment", y="count", color="sentiment", title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
    st.plotly_chart(fig_sent, config={"displayModeBar": True})

    st.subheader("–¢–∞–±–ª–∏—Ü–∞ –æ—Ç–∑—ã–≤–æ–≤")
    table_df = pd.DataFrame(
        [
            {
                "text": (r.text or ""),
                "sentiment": (r.sentiment or ""),
                "score": (r.sentiment_score or 0.0),
                "language": (r.language or ""),
            }
            for r in analysis.reviews
        ]
    )
    table_df = table_df.fillna("")
    # Ensure score is shown as float with 3 decimals in the UI
    try:
        table_df["score"] = pd.to_numeric(table_df["score"], errors="coerce").fillna(0.0)
    except Exception:
        pass
    st.dataframe(
        table_df,
        width="stretch",
        hide_index=True,
        column_config={
            "score": st.column_config.NumberColumn(label="score", format="%.3f"),
        },
    )

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞
    render_export_buttons(analysis)

    st.subheader("–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ –¥–æ—Å—Ç–æ–∏–Ω—Å—Ç–≤–∞ (–ò–ò)")
    insights = analysis.stats.get("insights", {"problems": [], "strengths": []})
    col_p, col_s = st.columns(2)
    with col_p:
        st.markdown("**–ü—Ä–æ–±–ª–µ–º—ã**")
        if insights.get("problems"):
            for it in insights["problems"]:
                st.markdown(f"- {it}")
        else:
            st.caption("–ù–µ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º")
    with col_s:
        st.markdown("**–î–æ—Å—Ç–æ–∏–Ω—Å—Ç–≤–∞**")
        if insights.get("strengths"):
            for it in insights["strengths"]:
                st.markdown(f"- {it}")
        else:
            st.caption("–ù–µ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ—Å—Ç–æ–∏–Ω—Å—Ç–≤")

    # Heuristic notice if AI expected but scores look zero-ish
    if use_ai:
        any_nonzero = any(abs(getattr(r, "sentiment_score", 0.0)) > 1e-6 for r in analysis.reviews)
        if not any_nonzero:
            st.info(
                "–ü–æ—Ö–æ–∂–µ, —á—Ç–æ –æ—Ü–µ–Ω–∫–∏ –ò–ò —Ä–∞–≤–Ω—ã 0. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω HF, –º–æ–¥–µ–ª—å –∏ —Å–µ—Ç–µ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ."
            )

    with st.expander("–õ–æ–≥–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ HF API"):
        logs = get_hf_logs(10)
        if logs:
            st.json(logs)
        else:
            st.caption("–ü–æ–∫–∞ –Ω–µ—Ç –ª–æ–≥–æ–≤. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ò–ò-–∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ—è–≤–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å–µ–π.")

    with st.expander("–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –∞–Ω–∞–ª–∏–∑–∞"):
        st.json({"analysis_id": analysis.id, "created_at": str(analysis.created_at), "stats": analysis.stats})
else:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å–∞–π–¥–±–∞—Ä–µ, –∑–∞—Ç–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑.")
